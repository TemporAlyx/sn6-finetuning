{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "from utils import *\n",
    "from training import *\n",
    "from validation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"llama3\" # mistral, gemma, stablelm\n",
    "\n",
    "hf_account_name = \"\" # huggingface.co username\n",
    "save_name = \"\" # name to save the model as\n",
    "model_name = \"\" # hf_repo/model_name\n",
    "model_name_to_beat = model_name # set to the same unless comparing against a different model\n",
    "\n",
    "params = load_local_config()\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, **params, cache_dir=\"Models\")\n",
    "model.config.name_or_path = save_name\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "tokenizer = get_tokenizer(model_type)\n",
    "\n",
    "model = norm_model_weights(model)\n",
    "        \n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name_to_beat, **params, cache_dir=\"Models\")\n",
    "for name, param in base_model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "trainer = Trainer(model, tokenizer, base_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     print(name, param, param.data.shape)\n",
    "\n",
    "print(validate_parameters(model, print_vals=True))\n",
    "print(validate_parameters(base_model, print_vals=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train(acc_batch_size=512, opt=\"adamw\", lr=1e-5, lr_schedule=\"constant\", weight_decay=0.0, betas=(0.9, 0.99), \n",
    "                warmup_steps=0, warmup_end_offset=0,\n",
    "                grad_clip_norm=1.0, ignore_overshot_samples=True, bad_sample_mult=1.0, ignore_sample_loss_below=0.0, precalc_batch_mult=2.25,\n",
    "                remerging=False, remerge_ratio=0.75,\n",
    "                base_relative_loss=False, loss_eps = 0.02, overshoot_buffer = -0.01, eval_eps=0.01,\n",
    "                eval_steps=512, revert=True, eval_revert_if={\"loss\": 0.004, \"head_to_head\": -12.5, \"eps0_head_to_head\": -22.5},\n",
    "                save_name=\"test\", do_save=True, cortex_steps=5, max_steps=None,\n",
    "                gradient_checkpointing=False, excessive_cache_clearing=False, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_improvement(model, base_model, samples=768, tokenizer_name=model_type, dedup=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upload_name = hf_account_name + \"/\" + save_name\n",
    "tokenizer.push_to_hub(repo_id=upload_name, private=True)\n",
    "commit_info = model.push_to_hub(repo_id=upload_name, safe_serialization=True, private=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
